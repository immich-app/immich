# See:
# - https://immich.app/docs/developer/setup
# - https://immich.app/docs/developer/troubleshooting

name: immich-dev

services:
  immich-server:
    container_name: immich_server
    command: ['/usr/src/app/bin/immich-dev']
    image: immich-server-dev:latest
    build:
      context: ../
      dockerfile: server/Dockerfile
      target: dev
    restart: always
    volumes:
      - ../server:/usr/src/app
      - ../open-api:/usr/src/open-api
      - ${UPLOAD_LOCATION}/photos:/usr/src/app/upload
      - ${UPLOAD_LOCATION}/photos/upload:/usr/src/app/upload/upload
      - /usr/src/app/node_modules
      - /etc/localtime:/etc/localtime:ro
    env_file:
      - .env
    ulimits:
      nofile:
        soft: 1048576
        hard: 1048576
    ports:
      - 3001:3001
      - 9230:9230
    depends_on:
      - redis
      - database

  immich-web:
    container_name: immich_web
    image: immich-web-dev:latest
    build:
      context: ../web
    command: ['/usr/src/app/bin/immich-web']
    env_file:
      - .env
    ports:
      - 2283:3000
      - 24678:24678
    volumes:
      - ../web:/usr/src/app
      - ../open-api/:/usr/src/open-api/
      - /usr/src/app/node_modules
    ulimits:
      nofile:
        soft: 1048576
        hard: 1048576
    restart: unless-stopped
    depends_on:
      - immich-server

  immich-machine-learning:
    container_name: immich_machine_learning
    image: immich-machine-learning-dev:latest
    # extends:
    #   file: hwaccel.ml.yml
    #   service: cpu # set to one of [armnn, cuda, openvino, openvino-wsl] for accelerated inference
    build:
      context: ../machine-learning
      dockerfile: Dockerfile
      args:
        - DEVICE=cpu # set to one of [armnn, cuda, openvino, openvino-wsl] for accelerated inference
    ports:
      - 3003:3003
    volumes:
      - ../machine-learning:/usr/src/app
      - model-cache:/cache
    env_file:
      - .env
    depends_on:
      - database
    restart: unless-stopped

  redis:
    container_name: immich_redis
    image: redis:6.2-alpine@sha256:84882e87b54734154586e5f8abd4dce69fe7311315e2fc6d67c29614c8de2672

  database:
    container_name: immich_postgres
    image: tensorchord/pgvecto-rs:pg14-v0.2.0@sha256:90724186f0a3517cf6914295b5ab410db9ce23190a2d9d0b9dd6463e3fa298f0
    env_file:
      - .env
    environment:
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_USER: ${DB_USERNAME}
      POSTGRES_DB: ${DB_DATABASE_NAME}
      POSTGRES_INITDB_ARGS: '--data-checksums'
    volumes:
      - ${UPLOAD_LOCATION}/postgres:/var/lib/postgresql/data
    ports:
      - 5432:5432
    command: ["postgres", "-c" ,"shared_preload_libraries=vectors.so", "-c", 'search_path="$$user", public, vectors', "-c", "logging_collector=on", "-c", "max_wal_size=2GB", "-c", "shared_buffers=512MB", "-c", "wal_compression=on"]

  # set IMMICH_METRICS=true in .env to enable metrics
  # immich-prometheus:
  #   container_name: immich_prometheus
  #   ports:
  #     - 9090:9090
  #   image: prom/prometheus
  #   volumes:
  #     - ./prometheus.yml:/etc/prometheus/prometheus.yml
  #     - prometheus-data:/prometheus

  # first login uses admin/admin
  # add data source for http://immich-prometheus:9090 to get started
  # immich-grafana:
  #   container_name: immich_grafana
  #   command: ['./run.sh', '-disable-reporting']
  #   ports:
  #     - 3000:3000
  #   image: grafana/grafana:10.3.3-ubuntu
  #   volumes:
  #     - grafana-data:/var/lib/grafana

volumes:
  model-cache:
  prometheus-data:
  grafana-data:
